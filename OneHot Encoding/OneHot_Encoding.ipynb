{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OneHot-Encoding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfwnbFWyvi/As6Rvk8tOJt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedHussein736/Natural-Language-Processing-NLP-Topics/blob/master/OneHot%20Encoding/OneHot_Encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrgH7wpiVMHg",
        "colab_type": "text"
      },
      "source": [
        "Discover how to develop LSTMs such as stacked, bidirectional, CNN-LSTM, Encoder-Decoder seq2seq and more in my new book, with 14 step-by-step tutorials and full code.\n",
        "https://machinelearningmastery.com/lstms-with-python/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOKzdOmohHeE",
        "colab_type": "text"
      },
      "source": [
        "##problem\n",
        "\n",
        "So far, we've looked at representations that tried to characterize an entire document or collection of words as one unit. \n",
        "\n",
        "As a result, the kinds of inferences we can make are also typically at a document level, mixture of topics in the document, documents similarity, documents sentiment, et cetera.\n",
        "\n",
        "For a deeper analysis of text, we need to come up with a numerical representation for each word.\n",
        "\n",
        "If you've dealt with categorical variables for data analysis or tried to perform multi-class classification,you may have come across this term, One-Hot Encoding.\n",
        "\n",
        "##One-Hot Encoding.\n",
        "\n",
        "That is one way of representing words, treat each word like a class, assign it a vector that has one in a single pre-determined position for that word and zero everywhere else.\n",
        "\n",
        "it's just like the bag of words idea, only that we keep a single word in each bag and build a vector for it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2sll02IsVWf",
        "colab_type": "text"
      },
      "source": [
        "There are some cases where LabelEncoder or DictVectorizor are useful, but these are quite limited in my opinion due to ordinality.\n",
        "\n",
        "LabelEncoder can turn [dog,cat,dog,mouse,cat] into [1,2,1,3,2], but then the imposed ordinality means that the average of dog and mouse is cat. Still there are algorithms like decision trees and random forests that can work with categorical variables just fine and LabelEncoder can be used to store values using less disk space.\n",
        "\n",
        "One-Hot-Encoding has the advantage that the result is binary rather than ordinal and that everything sits in an orthogonal vector space. The disadvantage is that for high cardinality, the feature space can really blow up quickly and you start fighting with the curse of dimensionality. In these cases, I typically employ one-hot-encoding followed by PCA for dimensionality reduction. I find that the judicious combination of one-hot plus PCA can seldom be beat by other encoding schemes. PCA finds the linear overlap, so will naturally tend to group similar features into the same feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29V9CMhItxnC",
        "colab_type": "text"
      },
      "source": [
        " **disagree** with the others.\n",
        "\n",
        "While you can use PCA on binary data (e.g. one-hot encoded data) that does not mean it is a good thing, or it will work very well.\n",
        "\n",
        "PCA is desinged for continuous variables. It tries to minimize variance (=squared deviations). The concept of squared deviations breaks down when you have binary variables.\n",
        "\n",
        "So yes, you can use PCA. And yes, you get an output. It even is a least-squared output - it's not as if PCA would segfault on such data. It works, but it is just much less meaningful than you'd want it to be; and supposedly less meaningful than e.g. frequent pattern mining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK4TtveRVKXm",
        "colab_type": "text"
      },
      "source": [
        "##cons:\n",
        "1. matrix is very large to cover all the uniqe words\n",
        "2. these repesentaion don't cover any notation of representaion\n",
        "3. IDEALLY, we want the representaion of cat and dog to be  both animals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av9YWmNkVDIJ",
        "colab_type": "code",
        "outputId": "57f08367-c43d-418c-b811-a498465f621f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from numpy import argmax\n",
        "# define input string\n",
        "data = 'hello world'\n",
        "print(data)\n",
        "\n",
        "# define universe of possible input values\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz '"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKuJGIGHWI3y",
        "colab_type": "code",
        "outputId": "9bf0483a-b2a6-4512-ad66-b2dd5a5bd8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# define a mapping of chars to integers\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "print(char_to_int)\n",
        "print(int_to_char)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, ' ': 26}\n",
            "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: ' '}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzFsDiN1V1AA",
        "colab_type": "code",
        "outputId": "8d1ef98d-7cfe-4175-bd81-d8e708bc295d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# integer encode input data\n",
        "integer_encoded = [char_to_int[char] for char in data]\n",
        "print(integer_encoded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 4, 11, 11, 14, 26, 22, 14, 17, 11, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuV0u866V1tG",
        "colab_type": "code",
        "outputId": "60f6cd41-4d1d-49e8-b1e7-12aea2789d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# one hot encode\n",
        "onehot_encoded = list()\n",
        "for value in integer_encoded:\n",
        "    letter = [0 for _ in range(len(alphabet))]\n",
        "    letter[value] = 1\n",
        "    onehot_encoded.append(letter)\n",
        "print(onehot_encoded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUDN3PMTV6YG",
        "colab_type": "code",
        "outputId": "4c330621-166e-4d55-e2bd-e3530a7c1323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# invert encoding\n",
        "inverted = int_to_char[argmax(onehot_encoded[0])]\n",
        "print(inverted)\n",
        "print(onehot_encoded[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpiG3BpoFy2C",
        "colab_type": "text"
      },
      "source": [
        "#######################################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGLY1FEvYQ0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqnIwghbFsBK",
        "colab_type": "code",
        "outputId": "b019fd94-234b-45c8-b9ea-5fefc71981b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# define example\n",
        "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "values = array(data)\n",
        "print(values)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm4iT5NHFuIE",
        "colab_type": "code",
        "outputId": "ca4c4059-b6bc-467b-cb94-b308cee8adf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 2 0 1 1 2 0 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odXqc3_jFc_i",
        "colab_type": "code",
        "outputId": "f09956a1-3536-4899-b829-1d5cd1f9d932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "print(onehot_encoder)\n",
        "\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "print(integer_encoded)\n",
        "\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
            "              handle_unknown='error', sparse=False)\n",
            "[[0]\n",
            " [0]\n",
            " [2]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [2]\n",
            " [1]]\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvo-EigbFvxx",
        "colab_type": "code",
        "outputId": "007b91c2-539f-4b52-eb97-e40d6af678fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cold']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1VUvdbRGt1y",
        "colab_type": "code",
        "outputId": "7e8456b0-a0e3-48de-9dd6-9d97cc3f4697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "# define example\n",
        "data = [1, 3, 2, 0, 3, 2, 2, 1, 0, 1]\n",
        "data = array(data)\n",
        "print(data)\n",
        "# one hot encode\n",
        "encoded = to_categorical(data)\n",
        "print(encoded)\n",
        "# invert encoding\n",
        "inverted = argmax(encoded[0])\n",
        "print(inverted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1 3 2 0 3 2 2 1 0 1]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDTPfRanM1h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}